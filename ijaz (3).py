# -*- coding: utf-8 -*-
"""ijaz.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15Qg_9MrfPWWY0HvGguh-uQHY1mP9NQ7p
"""

pip install pandas numpy scikit-learn

pip install pandas numpy scikit-learn wordcloud

"""**1. Importing Necessary Libraries**"""

# Import necessary libraries for data mining and modeling
import pandas as pd
import numpy as np
import string
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from wordcloud import WordCloud
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.utils import to_categorical

"""**Justification:**
This block imports all the required libraries for data manipulation, visualization, text processing, and building a machine learning model. These libraries are foundational for carrying out data mining tasks.

**2. Data Collection and Preprocessing**
"""

# Step 1: Data Collection and Preprocessing

# Load the dataset from an Excel file
file_path = '/content/drive/MyDrive/final_user_bot_comments.xlsx'
data = pd.read_excel(file_path)

# Check for missing values and fill them if necessary
data['review_text'] = data['review_text'].fillna('')

# Convert 'is_bot' to a categorical variable
data['is_bot'] = data['is_bot'].astype('category')

# Preprocess text by converting to lowercase and removing punctuation
def preprocess_text(text):
    text = text.lower()
    text = text.translate(str.maketrans('', '', string.punctuation))
    return text

data['cleaned_review_text'] = data['review_text'].apply(preprocess_text)

"""**Justification:**
This block focuses on data collection and preprocessing, which are critical first steps in data mining. Here:

The dataset is loaded from an Excel file.
Missing values in the review_text column are filled.
The is_bot column is converted to a categorical variable, which is necessary for classification tasks.
Text preprocessing is performed to standardize the data by removing punctuation and converting text to lowercase.

3. **Exploratory Data Analysis (EDA)**
"""

# Step 2: Exploratory Data Analysis (EDA)

# Visualize the distribution of classes (User vs Bot)
sns.countplot(x='is_bot', data=data)
plt.title('Distribution of User vs Bot Reviews')
plt.show()

# Example of a word cloud to see common words in User and Bot comments
from wordcloud import WordCloud

user_comments = ' '.join(data[data['is_bot'] == 0]['cleaned_review_text'])
bot_comments = ' '.join(data[data['is_bot'] == 1]['cleaned_review_text'])

plt.figure(figsize=(12, 6))

# Word cloud for User comments
plt.subplot(1, 2, 1)
user_wordcloud = WordCloud(width=300, height=200, background_color='white').generate(user_comments)
plt.imshow(user_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('User Comments Word Cloud')

# Word cloud for Bot comments
plt.subplot(1, 2, 2)
bot_wordcloud = WordCloud(width=300, height=200, background_color='white').generate(bot_comments)
plt.imshow(bot_wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Bot Comments Word Cloud')

plt.show()

"""**Justification:**
This block is dedicated to Exploratory Data Analysis (EDA).

The distribution of the target variable (is_bot) is visualized using a count plot.
Word clouds provide insight into the most common words used in User vs Bot comments, helping to uncover patterns and differences in the text data.

**4. Feature Extraction using TF-IDF**
"""

# Step 3: Feature Extraction using TF-IDF

# Define features (X) and target (y)
X = data['cleaned_review_text']
y = data['is_bot']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Use TF-IDF to convert text data into numerical features
tfidf = TfidfVectorizer(stop_words='english')
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

"""**Justification:**
In this block, Feature Extraction is carried out using TF-IDF (Term Frequency-Inverse Document Frequency), a common technique to convert textual data into numerical features that can be fed into machine learning models.

The data is split into training and testing sets.
TF-IDF vectorization transforms the cleaned text data into features that capture the importance of words across the dataset.

**5. Modeling - Random Forest Classifier**
"""

# Initialize the Random Forest model
rf_model = RandomForestClassifier(random_state=42)

# Hyperparameter tuning using GridSearchCV to find the best parameters
param_grid = {
    'n_estimators': [100, 200, 500],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

# Initialize GridSearchCV
grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')

# Fit GridSearchCV
grid_search.fit(X_train_tfidf, y_train)

# Get the best model
best_rf_model = grid_search.best_estimator_

"""**Justification**
This block ensures that the Random Forest model is optimally tuned for the classification task by systematically exploring various hyperparameter settings.

**5. Classical Supervised Machine Learning Algorithms**
"""

# Initialize classifiers with example hyperparameters
models = {
    'Naive Bayes': MultinomialNB(alpha=1.0),
    'Support Vector Machine': SVC(kernel='linear', C=1.0),
    'Decision Tree': DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, min_samples_split=5, random_state=42)
}

# Train and evaluate each model
results = {}

for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train_tfidf, y_train)
    y_pred = model.predict(X_test_tfidf)

    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, target_names=['User', 'Bot'])
    cm = confusion_matrix(y_test, y_pred)

    # Store results
    results[name] = {
        'accuracy': accuracy,
        'classification_report': report,
        'confusion_matrix': cm
    }

    # Print results
    print(f"{name} Accuracy: {accuracy * 100:.2f}%")
    print("Classification Report:")
    print(report)

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['User', 'Bot'], yticklabels=['User', 'Bot'])
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'{name} Confusion Matrix')
    plt.show()

"""**Justification**
his block systematically evaluates multiple models with set hyperparameters and visualizes their performance, providing a comprehensive comparison of different classifiers.

**6. Neural Network Classification using TensorFlow/Keras**
"""

# Convert target labels to categorical format
y_train_cat = to_categorical(y_train)
y_test_cat = to_categorical(y_test)

# Define the neural network model
model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(X_train_tfidf.shape[1],)))
model.add(Dropout(0.5))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))  # Assuming binary classification (User vs Bot)

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
history = model.fit(X_train_tfidf.toarray(), y_train_cat,
                    epochs=10,
                    batch_size=32,
                    validation_split=0.2,
                    verbose=1)

# Evaluate the model
loss, accuracy = model.evaluate(X_test_tfidf.toarray(), y_test_cat, verbose=1)
print(f"Test Accuracy: {accuracy * 100:.2f}%")

# Predict and evaluate
y_pred = model.predict(X_test_tfidf.toarray())
y_pred_classes = np.argmax(y_pred, axis=1)
y_test_classes = np.argmax(y_test_cat, axis=1)

# Print classification report
print("\nClassification Report:")
print(classification_report(y_test_classes, y_pred_classes, target_names=['User', 'Bot']))

# Plot training & validation accuracy values
plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend(['Train', 'Val'], loc='upper left')
plt.show()

"""**Justification**
This block sets up, trains, and evaluates a neural network model for text classification, providing detailed metrics and visualizations to understand its performance.

**7.Making Predictions**
"""

# Define the prediction function
def predict_comment(comment, models, tfidf, nn_model=None):
    cleaned_comment = preprocess_text(comment)
    comment_tfidf = tfidf.transform([cleaned_comment])

    predictions = {}
    for name, model in models.items():
        y_pred = model.predict(comment_tfidf)
        prediction = 'User' if y_pred[0] == 0 else 'Bot'
        predictions[name] = prediction

    if nn_model:
        y_pred_prob = nn_model.predict(comment_tfidf.toarray())
        if y_pred_prob.ndim == 1:
            y_pred_classes = (y_pred_prob > 0.5).astype(int)
        else:
            y_pred_classes = np.argmax(y_pred_prob, axis=1)
        predictions['Neural Network'] = 'User' if y_pred_classes[0] == 0 else 'Bot'

    return predictions

# Interactive CLI example
comment_input = input("Enter a comment to classify: ")
predictions = predict_comment(comment_input, models, tfidf, model)
print("Predictions:")
for name, prediction in predictions.items():
    print(f"{name} Prediction: {prediction}")

"""**Justification**
This block ensures that both classical machine learning models and the neural network model are used to predict and interpret new data, allowing you to compare predictions across different approaches.
"""